Ollama AI Chat/Voice Frontend


# Features

Connect to a ollama server and send messages to open source LLMs
Store message history
Speech recognition from microphone
AI voice via EdgeTTS

# Quickstart

### For End Users
Install binary from https://github.com/TheLp281/PromptLama/releases

### For Developers

## Requirements:
Ollama server running in your system
FFmpeg installed in your system (for speech recognition)

## To setup virtual env and install:
``` bash
make install
```

## To run server:
``` bash
make run
```

## Configure:
Available options for .env:

## HOST
Hostname to bind the server at.

## PORT
Port number to bind the server at.

## OLLAMA_HOST
URL of ollama api. Defaults to http://127.0.0.1:11434



## Todo:

Language dropdown to override recognized language
Set temperature of model
Implement model management ui
Export chat history button

